pull:
  - prefect.deployments.steps.git_clone:
      repository: https://github.com/PrefectHQ/canary-flows
      branch: main

definitions:
  descriptions:
    integration_tests: &description |
      Runs a test flow to test integration with our API

  schedules:
    every_five_minutes: &every_five_minutes
      cron: "*/5 * * * *"

    every_three_hours: &every_three_hours
      cron: "0 */3 * * *"

  work_pools:
    integration-tests: &integration-tests-work-pool
      name: integration-tests

deployments:
  # All deployments with environment tags for conditional deployment - alphabetical order
  - name: Automations - Compound
    tags:
      - expected:success
    description: *description
    schedule: *every_five_minutes
    entrypoint: flows/automation-assessments.py:assess_compound_automation
    work_pool: *integration-tests-work-pool

  - name: Automations - Proactive
    tags:
      - expected:success
    description: *description
    schedule: *every_five_minutes
    entrypoint: flows/automation-assessments.py:assess_proactive_automation
    work_pool: *integration-tests-work-pool

  - name: Automations - Reactive
    tags:
      - expected:success
    description: *description
    schedule: *every_five_minutes
    entrypoint: flows/automation-assessments.py:assess_reactive_automation
    work_pool: *integration-tests-work-pool

  - name: Automations - Sequence
    tags:
      - expected:success
    description: *description
    schedule: *every_five_minutes
    entrypoint: flows/automation-assessments.py:assess_sequence_automation
    work_pool: *integration-tests-work-pool

  - name: Automations Tracer
    tags:
      - expected:success
    description: *description
    schedule:
      interval: 30
    entrypoint: flows/automations-tracer.py:automations_tracer_entry
    work_pool: *integration-tests-work-pool

  - name: Deployment Concurrency Leases
    tags:
      - expected:success
    description: *description
    schedule: *every_five_minutes
    entrypoint: flows/deployment-concurrency-leases.py:deployment_concurrency_leases_entry
    work_pool: *integration-tests-work-pool

  - name: Deployment Concurrency
    tags:
      - expected:success
    description: *description
    schedule: *every_five_minutes
    entrypoint: flows/deployment-concurrency.py:deployment_concurrency_entry
    work_pool: *integration-tests-work-pool

  - name: Deployment Concurrency - Prefect 3.4.10
    tags:
      - expected:success
    description: *description
    schedule: *every_five_minutes
    entrypoint: flows/deployment-concurrency.py:deployment_concurrency_entry
    work_pool:
      <<: *integration-tests-work-pool
      job_variables:
        image: prefecthq/prefect:3.4.10-python3.12
        env:
          PREFECT_VERSION: 3.4.10

  - name: Events - Streaming
    tags:
      - expected:success
    description: *description
    schedule: *every_five_minutes
    entrypoint: flows/event-streaming.py:event_streaming
    work_pool: *integration-tests-work-pool

  - name: Flow Pauses
    tags:
      - expected:failure
    description: *description
    schedule: *every_five_minutes
    entrypoint: flows/flow-pauses.py:flow_pauses_entry
    work_pool: *integration-tests-work-pool

  - name: Flow Results
    tags:
      - expected:success
    description: *description
    schedule: *every_five_minutes
    entrypoint: flows/flow-results.py:flow_results_entry
    work_pool: *integration-tests-work-pool

  - name: Flow Retries
    tags:
      - expected:success
    description: *description
    schedule: *every_five_minutes
    entrypoint: flows/flow-retries.py:flow_retries_entry
    work_pool: *integration-tests-work-pool

  - name: Flow Retries With Subflows
    tags:
      - expected:success
    description: *description
    schedule: *every_five_minutes
    entrypoint: flows/flow-retries-with-subflows.py:flow_retries_subflows_entry
    work_pool: *integration-tests-work-pool

  - name: Hello Tasks
    tags:
      - expected:success
    description: *description
    schedule: *every_five_minutes
    entrypoint: flows/hello-tasks.py:hello_tasks_entry
    work_pool: *integration-tests-work-pool

  - name: Hello World
    tags:
      - expected:success
    description: *description
    schedule: *every_five_minutes
    entrypoint: flows/hello-world.py:hello_world_entry
    work_pool: *integration-tests-work-pool

  - name: Ensure Automations Exist
    tags:
      - expected:success
    description: *description
    schedule: *every_three_hours
    entrypoint: flows/ensure-integration-automations.py:ensure_integrations_automations
    work_pool: *integration-tests-work-pool

  - name: Secret Block
    tags:
      - expected:success
    description: *description
    schedule: *every_five_minutes
    entrypoint: flows/secret-block.py:secret_block_entry
    work_pool: *integration-tests-work-pool

  - name: Tag-based Concurrency Limits
    tags:
      - expected:success
    description: |
      This test runs a flow using tag-based concurrency limits to guard 
      against regressions during the transition to using GCLs for concurrency limits. 
    schedule: *every_five_minutes
    entrypoint: flows/tag-based-concurrency-limits.py:tag_based_concurrency_limits_entry
    work_pool: *integration-tests-work-pool

  - name: Tag-based Concurrency Limits - Prefect 2.20
    tags:
      - expected:success
    description: |
      This test runs a flow using tag-based concurrency limits with Prefect 2.20 to guard 
      against regressions during the transition to using GCLs for concurrency limits. 
      Prefect 2 handles tag-based concurrency limits server-side via orchestration rules, 
      which is why this is separate from the base tag-based concurrency limits test.
    schedule: *every_five_minutes
    entrypoint: flows/tag-based-concurrency-limits.py:tag_based_concurrency_limits_entry
    work_pool:
      <<: *integration-tests-work-pool
      job_variables:
        image: prefecthq/prefect:2.20-python3.12
        env:
          PREFECT_VERSION: "2.20"

  - name: Task Burst
    tags:
      - expected:success
    description: *description
    schedule: *every_five_minutes
    entrypoint: flows/task-bursts.py:burst_tasks
    work_pool: *integration-tests-work-pool

  - name: Task Results
    tags:
      - expected:success
    description: *description
    schedule: *every_five_minutes
    entrypoint: flows/task-results.py:task_results_entry
    work_pool: *integration-tests-work-pool

  - name: Task Retries
    tags:
      - expected:success
    description: *description
    schedule: *every_five_minutes
    entrypoint: flows/task-retries.py:task_retries_entry
    work_pool: *integration-tests-work-pool

  - name: prefect-dbt Integration
    tags:
      - expected:success
    description: |
      Tests prefect-dbt CLI tasks to catch regressions from async dispatch changes.
      See: https://github.com/PrefectHQ/prefect/pull/20300
    schedule: *every_five_minutes
    entrypoint: flows/prefect-dbt-integration.py:prefect_dbt_integration_entry
    pull:
      - prefect.deployments.steps.git_clone:
          repository: https://github.com/PrefectHQ/canary-flows
          branch: add-prefect-dbt-canary  # TODO: change to main after PR merge
    work_pool:
      <<: *integration-tests-work-pool
      job_variables:
        command: uv run --with "prefect-dbt @ git+https://github.com/PrefectHQ/prefect.git#subdirectory=src/integrations/prefect-dbt" --with dbt-duckdb -m prefect.engine

  - name: Database Cleanup
    tags:
      - maintenance
      - expected:success
    description: |
      Cleans up old data from the testbed database to manage disk space.

      Supports cleaning:
      - flow_runs: via Prefect API (safe, with cascade)
      - events: via direct SQL (for when built-in trimmer can't keep up)
      - orphaned_event_resources: via direct SQL (resources whose parent event was deleted)

      By default runs in DRY RUN mode - no actual deletions occur unless
      explicitly configured via parameters when triggering the flow.

      For SQL cleanup (events/orphans), requires a Secret block with the
      database connection string (configured via db_secret_block parameter).

      Configurable via UI form with validation:
      - Retention period (1-365 days, default: 30)
      - Entity types: flow_runs, events, orphaned_event_resources, all
      - Terminal states to include (for flow runs)
      - Batch sizes for API and SQL operations
      - Rate limiting delay
      - Dry run mode (default: true)
    schedule: *every_three_hours
    entrypoint: flows/database-cleanup.py:database_cleanup_entry
    work_pool: *integration-tests-work-pool
    parameters:
      config:
        days_to_keep: 7
        entity_types:
          - flow_runs
          - orphaned_event_resources
        dry_run: false
